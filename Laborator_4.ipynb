{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Laborator 8",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristinaGrigore/ML/blob/main/Laborator_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmaHAc_KHG_5"
      },
      "source": [
        "# Rețele neurale pentru clasificare imaginilor\n",
        "\n",
        "_Tudor Berariu, 2018_ (tudor.berariu@gmail.com)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKCKTWvsuJuF"
      },
      "source": [
        "În cadrul acestui laborator veți implementa o rețea neurală pentru clasificarea imaginilor.\n",
        "Rețeaua va fi compusă din straturi lineare și activări de tip ReLU și un strat softmax înainte de ieșiri. Funcția de cost folosită va fi negative log likelihood. Pentru optimizarea acesteia se va folosi SGD (stochastic gradient descent)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgNIWhzoHOIz"
      },
      "source": [
        "## 1. Setul de date MNIST\n",
        "\n",
        "Setul de date MNIST este compus din imagini de 28x28 pixeli reprezentând una dintre cele zece cifre 0-9.\n",
        "\n",
        "Decomentați mai jos comanda `!pip install mnist` pentru a instala pachetul `mnist`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQiqJyO7E7Ek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28a8d7e-46c4-4732-d0a6-0bf5b74d924b"
      },
      "source": [
        "!pip install mnist\n",
        "\n",
        "import mnist\n",
        "train_imgs = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "test_imgs = mnist.test_images()\n",
        "test_labels  = mnist.test_labels()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mnist\n",
            "  Downloading mnist-0.2.2-py2.py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mnist) (1.22.4)\n",
            "Installing collected packages: mnist\n",
            "Successfully installed mnist-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElGfqnPzuJuO"
      },
      "source": [
        "### Exemple din setul de date MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeftJ_CpE7Eu"
      },
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avJh9wQquJuU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "b00f67fd-cce4-4b72-a696-8b46a095c7a8"
      },
      "source": [
        "idxs = np.random.randint(0, len(train_imgs), 15)\n",
        "imgs = np.concatenate(tuple(train_imgs[idx,:,:] for idx in idxs), axis=1)\n",
        "plt.imshow(imgs)\n",
        "print(\"Labels:\", train_labels[idxs])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels: [5 2 6 4 9 2 4 5 1 8 1 7 6 6 8]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAA5CAYAAAAvOXAvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkgklEQVR4nO2dd3gU1frHP2dmN7vpvSekJ4TepCMiCogKomBFEVFQLxbQa7ter96rXgvYK6KABYGLHUEU4SK9hxogEAIkBAKE9Loz5/fHLhCQkt0NIfzufJ4nT3ZnJu/55p2Zd855TxkhpcTAwMDA4NJDudgCDAwMDAxcwwjgBgYGBpcoRgA3MDAwuEQxAriBgYHBJYoRwA0MDAwuUYwAbmBgYHCJ4lYAF0IMEELsEELsEkI81VCiDAwMDAzOj3B1HLgQQgV2AlcDucAa4DYp5baGk2dgYGBgcDbcqYF3BnZJKbOllDXADGBww8gyMDAwMDgfJjf+NhrYX+d7LtDlXH/gISzSircbRRoYGBj871HKsSNSytDTt7sTwOuFEGI0MBrAihddRN8LXeRFQ5hM1F7eFpuXivXnNWAsU2BgYNAALJCz955puzsBPA+IrfM9xrHtFKSUk4BJAH4iqFEjmhoSTEWXRDz3lqJv3XHBA6rWozUtX9vEvvIgqn7zQFZXX9DyDAwMTkX2aEf2jVZM5YL470qQG7a6ZU8ND2PPmGRsXpKk2aWQsR1pszWQWvdxJ4CvAVKEEAnYA/etwO0NoqqBqGkdR5cX11CpmdlaFMuevBBS3q+FtdtA1xq0LFNCHEefLOXliCUM2HI7PvqxBrV/qaC2SGX7/YH4NiuBRYFET89CO3z4Ysu66JQP7ULp8BIiX1SRa7dcbDn//1BUKm7ohPUvB1iTOpPDuuQan8dI3uCGTSEovDqRf9/5OZ0sB7kmbTTNxoZhyzvQYLLdxeVOTCmlDRgLzAcygVlSSvcedw2M5qFwue92Xo9cztz0b9jQ931GffkjrdZI9v2jO6aEuAYpR5hM7Lo3igVtvmR9jZXihRFIreEeEHrv9ly5uZyiu7ohTA2U9RICxcsLNTgINSTY/hPgD4rqmj1FRWmbTtDkAlYOeYPfO07m9Yc+obZ5TMPoPV6MtzfVv8Zz6KHuqKF/Sgk6RdnNXblt+wFK5iWx5+Vu1PbrhBoSjOLlheLl5bovTsMUEU75ncUs6zSF7McaxqZitf7p3DXUtaGmp2D+byQ5/+rWIPYuNKbICPLHdeFfr3/C7LRZ1CJZXpmA10H3prnIrm1IH7uV7tZDjN59M0+1mM+ha9yLGYrVCp1bs3NKRwKXBTFyx17KfknEFBnhkj23zriUci4w1x0bFxLPVVk8++Y9zB+5hqfDFhGiejLEu5Ah3oW8cN9yurcfSewjsdj27j+/sbOhqBQOv4z/3vk62TYTY6Y9SPz7G9EbsIavmxQeDdrGz3e0Ql0SjW3PGdNh9UaxWqns25rc22083WEeuTVB+KpV5Nf4s3FsG8TyjU7brOnXgU4vr+WvoUv5sPAyvsrsxEOtF1P5t2J8h/mil5Y6ZU9YLIjmiSilldiyc+qIV3grZSbl48w8cfABfP7jeu3eO7eSct3CzJbTWJkUjTrUnmL7+6ZBaJpCwBxvgr7f4rT206lJjuSq2I1YhJlOzfZx1A1bwmKBNqlsH2Nheb+3CFE9Afi8JJq3PruR6DdXu93Ez+8Tysdx03nadpNbduqNEJjim1GVEIIlrxg9ex+ytqZef6r4+rL9yXiW3vgaZiGYVNSGLz7rT/SvhURtWe6yJDUkmPynqvk25jdaz3uUFn/fx7Sk6wkUlS7bNCXGs+3xML4c8BFBShXzy1uwoSKO11JnM+b9O2l2Xw3a0ULnbLqs5gIiLBbUoEDKOjY76zE+a/eiFxWjV1Wd9RitqJjwyevYntGSnsM60q3zdvoEbuc2331YhJn32nzNuP4PEDLJ9QCu92pD+wczqAUGz32Y9Pd3oJWXu2xPWCyUXdcOv81H0HbuPmXftVFb+C2+F6obAVxYLBy4vwPXjljKusJmvD35RmKnZ6NFBFP7eimF7bwJW6k6lWJSfH3Z11/l29Bl/OPQFWQ+1oqUfYV88V5n5reZxqCrx+H17SrndKYkYHujjLIaDwKeSkffmGnfoet8XdSFp0KWUxaj4qM4p/WUMpZv5IMvrufIrb789E5vEHCslUSaJNJT40hHScjSILcCuLBYyLvCiykhS/iuPJqNc9KJwbXAYooI58CNSVx17wqmhCzhmQPXsHhHClbvGl5p+y1f/eUN7jk2jtC1xcjM3S71wQiTifJmkkRTDXu2RZLCPpe0ntG2xYJsm4pusYcd07FKlPJK8q6PxjqggFmt3ua2bXfh83xzWLnpvPbUAH/239uS8f1+okhXGLb+PkIneRG9ZCO6G/cgQN7wND5u/S5moRL1q4Lt4CHEwUMIF+0Jswf7boxi7sAJ7KgN457pfyHhhzLUg8eY/e/2TOk+hSeuuR//L1c6ZbdJBXC1ZRq5A4IpbVVNfMwRhkbNP+uxk3b2oOxQHEkzbaiL1p/1OFldjViWQcpaC0daJfNe1xYEPPIlg7yPEaxUYvN29ZSAmpxA3iM1zIr8nYf2X0eLCQXYjrhTvwJb95b0fW4pP+1tRdi/WiPXbEap0SnV61cjORfCYuHA2I48M/prnl17AymvVhK5ZRU2XUMUHmPP9nYoiTrhZhOy2okA7u9Hty7b8VEsLMlLouwaK0ptFIMiV+KlmDnaUsXrW+e0ViT4cUfUH9zum02nG8cTd7xRoGkszEvlxbB1lDXTUTytbt2sfjk6VqWWwB2VKEszCD7+P1mtCF9fbEeOuGwb7DW56D778VVUnvnpNlLe2Yjugh1TRDiZr8TwVo+pFGo+9Jr1OEmzykndsAU1PJRn3xvMkk6f8dyT0/j8YHeOvtQGj1/WOK83MgLP5kVYhUrCDw3XWVc+tAsHb6ymb/IO/Ez2Stee8mAOlvsxNe1NWnuYAS/ubLaKGUEDsZzHnuLlxd4HWvLPkfZ7uc/m4TR7shIta6tL/q2L2jKNW+75nTYeGhOPtsYr3/3BCGpUOL1vWceqqnjeefsmEqdtRK+owAboteF4oFHjI1DTUyC/AK2ouF52m0YAFwKlTXNCPsrjlchpxKo6PoqFddVQpHsB8F1hB35f0hYkICD2VxshQqJZVOqTVZTV1ai7cym93ZcOlgPUSg9Gb7+D6C+zcDXZcbRbBDM7vIGGZMfkdIKyV7ho6SS7bzYxI2g1fX23Mr7NAwSvAXPmPuaUJ7htu6pvG+64+zeeXTeYtCcOndIZI6ur8d6nUh6nIVQVp8brqArhlhIAprf9jOo2Kq8cuIZIj2IKtWoSvjqAs6GgIkSljcXeMrIU1dmhKKQEHkZHR60Wbo8sOtZcQZN/zpXqVVVwjtZdfckfFMdXSRP5+8HeJE8vdflhU9GuGe/2/IIJe/rj8Xd/UrZuRS8tRQKlnaK5J+VXvIQHFbqFdVnxxLlYL9GDfGkdls/CyiCsW3OdPm91ERYLtT1akT1M5cUrZzPEOx+LODXk2NAwYUZH8o+C9nwztwdJq3ac956suLIVU0a/TXsPhdT5Y0ifWIqWtcMNtScpaR7AQN9NzCqL5YfXryRwzXrn7oczYdPYVxFIv4DNhG4oR6+oAEBp05y7O6xgSUUq1YGC6KkH2HYsHN/ryuuVCrvoAVwNCSbriVRmDHubULWG8XtvYMePqXgUSyIW5KMfOAiAlDrJ2toTf3finxP1u1JNEeHsfiCJ34a+RozJk2VVZo6uisDncLZrulukctnD64lSJR1/GE/qV38+yYq3N9Jmc6op6xNRhr9iZWNlHGHLj6ABsrKKUs3TJZ3HMUVGkHWrxpqiONKePHLGnvRmsw9QEx2IrHGuti+LS/hldlfyrgvAW61h06TW+GdXkzOhlL1enifOoTMEZFcxp6Qd6SGrMZWf9KwwmXg4cgEVei1aTBW7nmtLwk+ViGUZTpcBoJslVqUWm48Zi9mj3rnXeiEEFX3KiDOZmLujFam5eS5XFjSL/Tq3fRiBx8pVJ2qZppho9veHob5b+KYslk9H30DasgyXO9F1i4lIazGPrbmZkD5W/L4+5LQNYbGgXZbO/n6e9B6QwdzoPzChUi0hT6vgh9KW9PfZRpLJExMq+2wVXL9uDCGTvUj4dQ3aeQKXGhhI5QPHaGWWjMi5ipRPatEyd9k7ngG9qtr1tJrFgm3UUZLNkgn5LQj+dTc69uGEsrjknCnbcyFrasktDqJdQgFFqd4ErBKoYaHs/psH47yz+P5YRxY/+Dq5NhPDFj+Kj16/NOlFD+AVlyXy8LVzmVfahmm/9CFlyhGiMu05wno9/c9XAxMCNSSE7ROiWNDrNcJVD9ZVw+MvjyFhxqnNWWEyocZGQ03teYcKHbgqhJ+iZnD9zqE0f78QrU6QVv38KOvTnAO9FDyOKQTu1AhYd+jUzrjzoCFAO7UxGGIqrXeL43TKOjZjSMu1LHm3C4F5q89cZl4+yp69OLs+jlZUTMy/l1PyoT8lwkzQsRWUD+1C/4DN3LZoDGm2DKf1mg+WsrMsDD1YYimRoKiYmkVT0iGSGNNcfBRPtveZzBuFzfnE3JekZU4XAUBtqI3rfDfz7aPtONy2E7Hzi9AzGmY5H1NMNJ92msaKak+Cf7GiHSpw2ZZHsY1aaSJ3oEb6Aj+0khJMifFkveTP8h5vcF/2MKpeiERd7F5tsSbISl+/bcwu78SxdIGfCzZKB7fHOvoAG9O/wYQKqLxblMiUrG5UbQlA94DagSqPBO5ic00tNy5+hPS/5WPL23p+7UJQfHUab6Z/wLyKEHZObU5IVQmlN3Wi4DIFKSBwG4T9utel4X5VV7bh7vi5mIVKC598vrnhSqqCBWF98shfkUTEKhve2wqw5exzrvVXXU3xrkBq20Lc6J2UbGsJ5dVIXTC/uDX/jlzEp0WtmTGhP8kzNtR7EMRFD+A2L4VQUwk7KiKI/6kKuceNESFnwBQdxfbxsczq8Q4xJk9+LA/k2enDSfh++4nORtXPD+HrQ/6gOGz9i9B1hdg7i8/a3FVDguk/cjl5WgV7FscTv+dkDl5p1ZysOwN5ach0bvK2jwXfbatkwOKHaD62EK2k5Jx6K8otVMtaIkzFVMcGYNp5ct9A71282ttE0h9eJ5pg9cHekaaQWOtN8IaiM14cakoie26PIGH2UbStrjVFtaJiFG9v1JZp5HcXRKvFUO3aUC59dw5b5nfm4KifKB5WSlFyF8ydjvGXtJ8Id4y8WF0tmPrN1STPKXEpaClWK1e12UZObQAhnuU8cM9MpvbrjumxFg0SxPcPa0YLcxXvFLbCN9e9PKp5XRYvbLuOyX2mMH7kGMIyKtk5RrK65weM2TuYmqfDUFe6M+jZTo2fSqK5EL8tZqI+2+xSPrk4UeGmiC3USo0Pi1P4YPPlhM/0JGblXop7+HH531bwUGAW+VolQxaMI/3VM7cIz4TSNh195GFSzJU8sXMoRzvbSL47nwfDVtLb8yjVUier1pPhl99H8tRwlMXO+aQizES8h73f4zb/dVz39EZUJBoCNUWy+ZYonl40jPQnjp33Xq6LVlJC2keH6Rf6EIt6v8uIf9+B6Z9BqDs8GdN9CQsqIvnqnf6EfrkG3YlRRBc9gPtlHuPlzAEs6DiZie9U882CbiRPL0Fu3O72ZBvF15c9I+L46oZ3aeOhMq/Cl398OpyEydvRy8qhc2vy+viidDtGu/A8HgmdTHdrKRZhZrBnPzhLAC/vlsRjIT/y1pHuxP5afqJZpaankPO8iZ8vm8D2mlBSZz2IR0w5i7t+xOtdZ/NR25tQlpz7gkqYLPiwXUtG+m/i3b8e41i37uhmaG1dQZjqxW0D/2DtR4noe50I4KqKHlLL7uIQfEsr/3RTmqKj2P2SN56WQvjavY6rwpva0PGhDTwf8iWpZgFWHcXXF+2YcxObpM1G/EdZ3NtjOIs6T6KoEySYrJiFiiYFM8pCee2DW0j4PNNp23XL2PpGO7aorQnYVMRHKUPp/twqvnuqDSmPR2PL/dPEYqcoa1dFLZIvt3YmZct+l9MnAHppKeH/MrFocgv+NXYqmVXRjArI4KfyOPLfSMZr5eoGmWlsswhCFXu6Ri+v/zVWl7hZB/h5dR8+7TqAoEyN5OV70IuKqencgvjxO3gmdDVgptdvj5L+Vgladv1Guqh+fuwc7sfClhPwVyw8kvg7vVrk4a94MDz7WsavScJyROHBO39icd+3GeB7P/Hbw5xq+QiHC1dVmxn7/iME7D55P1T7qUSOymZ2//f46+wHMC9Y54xb0HbuJu2VNG4PvYvvW37B1Y+PwtdURpHuwcsT7yDs8w1OBW9oAgFcy8widmwUgyaNYH6bL3jolqV8fU1bJm/tQeQ0C16rdjs9NhIcIy7uac0no96jo6NLe0ZBF2LnF5E7ojldbtnI3aHTiFIrCFVNWIQZHZ0KXeeFgk5QU3tW27l9FBTg26y2JGzcZQ+IQnDgqlCWdZnAxKNdWf1gB5r5aYQ+ewAvoTItvzseewrOmxZSF2/gg1V9GN1/C3NafklRuo4qIETxQEcl1XqQtUqyU77QKysJWuZBh/v3k5HWHs+D9gtaCQvhwMAYeoxcR3vzfpY82w0ty/mRCzj+f9m9LX3HLePJ0FV4CQ8AFvR9i2s/foD4O8qdzi9rhw8TcK8H1wx8nJvGLiTOcoRSzcoo/33sqgonLKPS5eAN9gDu+x/7/6vrGl5bBXNTuvPsPbP4uNtN+PzH9QCutGrOmPZLOKwpeK/wapDZqHLdVpY92YWEtw7zeNAO9tkkb78xjNAf1zid9joboiEeAtk5mLJziF1mQdba0HQNU0w0+Y9VMSVmDhVS0HrOw6S/cRQtK7v+Dx4PMzK8mkjVk9H7ryDFq4CdVZF8/3Yfwn/ZS0rRZqTNxpQj19Hrb1mMSFvFotguUM8ALsweVIYIApQKFpS1JOqdtadcs77RUWTfGATNAMW1XmJt2078R4aTu9zEwg6fsbnWixHTHiF+2nqX8usXPYAjJbbcPAKHetHlqfEkX57DAzGLmNv1A+gK/b57nLSXdjt9AxQNa8/34+0dlseZFDePoh9tBCkemIU9k1wtTRzQNBaWJzE1pxu1P4QS8UM2WsnZO2/UqApKdYnc4XMizWJKiCNwUB5+ipWvF/XA4yqFcbd9T0drDsN3D0a724Ittx4dE1KSdv8mOj8/nkHXrORa/42Eq2X4CtufevDrjZSELS5gyaBEnnl7JotL0rBJlQTPrbS2zqetx1F6/edxkuY4Nwb1BIqKdnlb4l7ZiYZCh0UPMu/y9yjUrISq8EybecyM7m7PGzqJLTePkEl5LJ0RzlKPGPTYCK774WOsSi3SxZsIONn5XbeVJyXNPt/Nztsjye8FaXO9XR41sm9QEEP8MlhfFUNohuuTP05BSjxX7OTFxYO4+/qP+K0ildBp6xt0bQ5Lkc76Gl+Us9df6o2srrb3QaWncHgCrGg7jcxaD0ZuHEGLVw+5PCFta42NnRNbsOqWOPy/9SF4+ooTFSPFy4viJAhSbFiU2noPcgBQ/H0pTa8lzVzNPKmeErzVkGCO9mnG3cm/MnztKOKXZbo2XFFKZG0tGgIfxcKUgl4kTD+E5mLn6MUP4A70igrinluBHhrKqz3u4kAvhYXDJvD3Ad8ydf5gLPOcC+AR9+05JXgDWISZcNVMhaxhbbUHqyqSmLK9G1qmL4mziwjak4dWsuu8tWTtoBfeiiCoUwFV13fGcrSanN7eLE+fCFj4ccibBCka4/YP4v3ZNxDzXS62nPpfrLK2hvi/r2bbp3H80aMrZbECvX0pm7pPdcoHp2jeuZvQf7bmqaF34JVWREWFBa9VHShpXcPTPeaS+lGBy018NTSYw+PL+Tl2Ec3nPkj7tBzMSO6aORZbZA3f9v6A12+OIer1/S4384/nG5XqGop1lZ7eO/guui/+wvmhhMLsQU3v1ti8VbzmZpxyo0pNJ6ciGOmtIcyu3R6Kry8VyTWEqwrPrr2B5BWb3R+GdlxfQjSDL7P3uXS27uH7Zl3ttdgGoipQxVvU4H1Ia5D1gpSWaeQ8b+K/bT5mZ62J26c/SvKkXNdmP0uJXqOSbJaEP5RN7afJBK45hG6xgC5RUuLJ6x/CY4N+IEjxYOGR5ijFFfW+rrUjRwldmsqaPv5YhA01MAyAyi7J5AwWPHvF92wsjyXuFd3lB7vi7c2ux1NJNP2Egom2vvuZb412yRY0oQAO2J+WAb6olTpqpYomIUgtQ/dwvqZ1a8SpIy10dHbV2njj4NUszGhB8BoVn3wb8ev2oh3OdGrqe/xPtWQN8mRuqy+Y/moameVR3OKzFx9hz9VEqZLO0/9K0qwSIjetxebK0DRdw5adQ0B2DgGA1qcDezpXEaqWoPu7tqa6XLOZpA0mhKcnaBpKeChxww/x7+UDSduT4ZJNAGG10Cc6CwUFFMnEuO+YU9aSqCU2PA9UMjp0uP04VXW/tqhpfHj4CiZGLaWwhSDQYnG66amGhbDnZgWfnSa8Tv9fLB70DNjGht0t0MtdqzmL2EjaJ+/FS3hg3ezZYDVkYbGwc4Q/Y/238HOFDx0sBVSkBmNpwACu2CSK0LF5Cvv96EZKRW2RSvZzZn7t/CGlOozacidJr2/DVs9JKqejl5QRvsjEpC4t+DLxZ757JpIJ26+mLLMDQkJqtxxej/mODpYiXjjcg6I3m+GVffZJfmdCSNBR6O+7memfdgJgROpCbvTdyJsFfVn6eUcit290+YFcfnVL/jlkBod1ydyKUEb4beNnvytcXpTqvAFcCBELfA6EY59GM0lK+bYQ4nngPuB41fgZx9ooTqNYrWR91pyE8KOkB+zjMp/FtLPkEqqamFHQBWuB8z34r715K1FPfEiAUsVzewezeX0CoWshaEMh6Yd2nciru1LH8Fi2lbETxpJy+w7+ETOHCFMxb2ZfxYu5QVj3eWA9AilfbnGql/p86GaFKFUlSi3licsDCM9wzY602ZCOqeFHe0fxUOAv7Hk30enOk7Px3ZXvU6yb+fjza2m2eoe9VvNQPFRmY2uIMnSdVYfiMEWtwOarg+rCoEqLPT8fuqnmT3n5nQ83wyzWEbLZ5vKY8LLUAEZF/IKOTsRK9ycDHUcNDWHWkHd4ZMetHC31Zm7nDzmWYsa1ZZDOjKVE47DmS42PAKGAdK0Wrvj6kjhtL1MjFhKseNFi6d0kvVBV7xmGZ0LW1hD47Sb+o/Xjv/en8k3yzwzp+Dn57eznqZnJk2N6FZ1/f5iUD2rwXLsO6WQrIuSPPF7cdS0/t/qK1Z2nALDXZmN01u2Yng0gcutml2vfpugoCm6v5BrvA9yWNYyewbuxeOc7leb5k816HGMDHpNSrhdC+ALrhBC/Ofa9KaWc4HLpDvTqapIn1pI1LoRBEZvwVqoZtPRBvDd4EvvVbsSh86+LcDqhk1bzyozeAMjaMlJq1iNttWgN0EmjV1UR9tEqSqdZ+at5AAC+NQdJ0/JA05C6RGvg5WqPYxFmilvWEu6mHTUwkCNXVvPMthsI3+3+0M1K3R4Ua1C4fcV9pE7efuIh6cz49/MhpaTwmDdlshqP8ApEfAw4OexRFh5DLY2g1+tLmBd5OSE/bENYreSMTOKtGz9j7IK7SF+83aWHuzCZKGlmIsWjgO/KIrHscH4W6tkobxtFoslGXk4IADrgUdywa9xLReCrVFHrIxCKQLqQ6DXFxrD73mbMiJyIl7Cy21ZJwM/eaJmb3danV1TgN3MNtoXBtBg/lst7b6alzwE++KUf5jKF4C0aaXM2ujzhxpazD79xKVxx5WOUR0tqAzUiFysE/JKJVrTPvWn6Fg9C/MrxEh6Mil7KZdYDvHykG+bC+qd5Tue8AVxKmQ/kOz6XCiEysb9OreGQErluK8l3Cub5xoEST3Jxhr2D01WbuubW074+9t1dMMcZPA5X8vLhzowPWYGwubdMJgCKQAhJ1ZpgZNUet0zphUUsnNuBO6/yIvuTNJKmrWyQB+WZkNXVpE6o4gq/kXzTeRLXjXuI1Huds6EVFZP25n5mVF5O37EbmH9VOmEhJdwc9V/GLriL5o9tdXlBMjUiHNG3kJfzBrJpbnOaHT7zpClX8N5ykCJd57YuK7Eo9jsjZN0xt9f+qItnbjlfHO6BqVch4mPPE601Z8h8PIYNN00EYGxeT1Z90Z6o77c03DWha2iHCkh8soBcIBc/kjjZAe+uP7TMLMIys07d5qZNAP3QYUrnteX92CRG+meyqDKCmb/0JCXP9TkHTr2VXggRD/wBtALGA3cDJcBa7LX0c47p8hNB8v/zK9UuJGpwEAVD0ihOhqSZDfCmkQB/MiekIKpV0h5zvcZysTAlxpM9PArvPEnwp66tQSMsFvQOzcnt643QIGx9DZbfM5rUG1fqonh5sfuzZNb0/JgdtSZGZYwg9r5DaG4uoFYXNcCfg7e1oCpEEDcxw6kJY8epGXAZ+69WQRck/FCJsnxzg79A5VJFDQykqF8aBZ0heKMg5Lc92PLPv9TEAjl7nZSy0+nb6x3AhRA+wGLgJSnlt0KIcOAI9rz4v4BIKeU9Z/i7uu/E7NhTDKxXeQYXGEVFdmmF5mnC/MfGJhu0DE5FTU7gSM8IzBWSgLUHGzQ9ZdB0cSuACyHMwBxgvpTyjTPsjwfmSClbncuOUQM3MDAwcB6XA7gQQgDTgEIp5aN1tkc68uMIIcYBXaSUt57HVinQMGs+XhhCsLcqmiqGPvcw9LlOU9YG///1xUkp//QOwfoE8J7AEmAzJ/sHngFuA9phT6HkAGOOB/Rz2Fp7pqdIU8HQ5x6GPvdoyvqasjb439VXn1EoS+GMbxJqsu/CNDAwMPhfoAHGoxkYGBgYXAwaO4BPauTynMXQ5x6GPvdoyvqasjb4H9Xn1DhwAwMDA4Omg5FCMTAwMLhEabQALoQYIITYIYTYJYR4qrHKPRdCiBwhxGYhRIYQYq1jW5AQ4jchRJbjd2Aj6vlMCFEghNhSZ9sZ9Qg77zj8uUkI0eEi6XteCJHn8GGGECdnagkhnnbo2yGE6H+BtcUKIRYJIbYJIbYKIR5xbG8S/juHvqbiP6sQYrUQYqND3wuO7QlCiFUOHTOFsL+pQwhhcXzf5dgff5H0TRVC7Knjv3aO7Rfj/lCFEBuEEHMc3y+876SUF/wHUIHdQCLgAWwEWjRG2efRlQOEnLbtNeApx+engFcbUc/lQAdgy/n0AAOBedhHCHUFVl0kfc8Dj5/h2BaO82wBEhznX72A2iKBDo7PvsBOh4Ym4b9z6Gsq/hOAj+OzGVjl8Mss4FbH9o+ABxyfHwQ+cny+FZh5gf13Nn1TgaFnOP5i3B/jgenYJzXSGL5rrBp4Z2CXlDJbSlkDzAAGN1LZzjIY+8QlHL9vaKyCpZR/AKe/P+5segYDn0s7K4EAIUTkRdB3NgYDM6SU1VLKPcAu7NfBhdKWL6Vc7/hcChxfdK1J+O8c+s5GY/tPSinLHF/Njh8JXAnMdmw/3X/H/Tob6CuEG+uiuq7vbDTq+RVCxADXApMd3wWN4LvGCuDRQN01S3Np6BUNXUMCvwoh1gn7mi0A4fLkhKSD4PbKre5yNj1NyadjHc3Uz+qknC6aPkeTtD32WlqT899p+qCJ+M+RAsgACoDfsNf6i6SUxxfKqavhhD7H/mIguDH1SSmP++8lh//eFMLxVpXG999bwBOcnOwYTCP47n+9E7OnlLIDcA3wFyHE5XV3Snsbp8kM02lqehx8CCRhn5WbD0y8mGKEfdG1b4BHpZSnvFGjKfjvDPqajP+klJqUsh0Qg7223/xiaTkTp+sTQrQCnsau8zIgCHiysXUJIa4DCqSUzr2mvgForACeB8TW+R7j2HZRkVLmOX4XAN9hv2gPHW9qOX7X75XWF46z6WkSPpVSHnLcWDrwCSeb+Y2uT9gXXfsG+EpK+a1jc5Px35n0NSX/HUdKWQQsArphTz0cn7FdV8MJfY79/kDDrWtbP30DHKkpKaWsBqZwcfzXAxgkhMjBnh6+EnibRvBdYwXwNUCKo1fWA3vi/sdGKvuMCCG8hf0NQwghvIF+wBaHrhGOw0YAP1wchSc4m54fgbscve1dgWJ5nrVoLgSn5RWHYPfhcX23OnrcE4AUoOHebvBnHQL4FMiUp66Y2ST8dzZ9Tch/oUKIAMdnT+Bq7Hn6RcBQx2Gn+++4X4cCCx0tnMbUt73Ow1lgzzHX9V+jnF8p5dNSyhgpZTz22LZQSnkHjeG7huqBPd8P9l7hndjzan9rrHLPoScRey//RmDrcU3Yc1G/A1nAAiCoETV9jb0ZXYs9ZzbqbHqw966/7/DnZqDTRdL3haP8TY4LM7LO8X9z6NsBXHOBtfXEnh7ZBGQ4fgY2Ff+dQ19T8V8bYINDxxbguTr3yWrsnaj/ASyO7VbH912O/YkXSd9Ch/+2AF9ycqRKo98fjnKv4OQolAvuO2MmpoGBgcElyv96J6aBgYHBJYsRwA0MDAwuUYwAbmBgYHCJYgRwAwMDg0sUI4AbGBgYXKIYAdzAwMDgEsUI4AYGBgaXKEYANzAwMLhE+T/K62ymTX+HLgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFP9QnUJuJuY"
      },
      "source": [
        "### Standardizarea datelor\n",
        "\n",
        "Datele de intrare (imaginile) vor fi rescalate pentru a avea media zero și deviația standard 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWmt4XVxuJuZ"
      },
      "source": [
        "mean, std  = train_imgs.mean(), train_imgs.std()\n",
        "train_imgs = (train_imgs - mean) / std\n",
        "test_imgs = (test_imgs - mean) / std"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgERUA07IuSr"
      },
      "source": [
        "## 2. Construirea unei rețele de tip feed-forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE-V6sONuJud"
      },
      "source": [
        "### Notații\n",
        "  - dimensiunea datelor de intrare este $D = 28 * 28 = 784$, iar dimensiunea ieșirilor rețelei este $K=10$ (numărul de clase)\n",
        "  - rețeaua neurală va avea $L$ straturi\n",
        "  - $B$ va reprezenta dimensiunea batch-ului (numărul de exemple trecute în același timp prin rețea)\n",
        "  - Vom nota cu ${\\bf X} \\in {\\mathbb R}^{B \\times D}$ un batch de intrări $\\left\\lbrace {\\bf x}_0, {\\bf x}_1, \\dots {\\bf x}_B \\right\\rbrace$ și similar ${\\bf Y} \\in {\\mathbb R}^{B \\times K}$\n",
        "  - ${\\bf x}^{(l)}$ reprezintă intrările stratului $l$ (${\\bf x}^{(0)}$ va fi o imagine precum cele din setul MNIST de dimensiune $D$)\n",
        "  - ${\\bf y}^{(l)}$ reprezintă ieșirile stratului $l$ (${\\bf y}^{(L-1)}$ reprezintă ieșirile rețelei)\n",
        "  - ${\\bf \\theta}^{(l)}$ reprezintă parametrii stratului $l$\n",
        "  - ${\\cal L}$ reprezintă funcția de cost (_negative log likelihood_)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YTu4tS8uJue"
      },
      "source": [
        "### Straturile rețelei\n",
        "\n",
        "Unele straturi au parametri ce trebuie optimizați în timpul antrenării. Vom nota parametrii stratului $l$ cu $\\bf{\\theta}^{(l)}$.\n",
        "Fiecare strat pe care îl veți implementa va avea trei metode:\n",
        " - `forward` calculează și întoarce ${\\bf y}^{(l)} = f_l\\left({\\bf x}^{(l)}, {\\bf \\theta}^{(l)}\\right)$\n",
        " - `backward` primește $\\frac{\\partial {\\cal L}}{\\partial {\\bf y}^{(l)}}$, reține intern $\\frac{\\partial {\\cal L}}{\\partial {\\bf \\theta}^{(l)}}$ și întoarce $\\frac{\\partial {\\cal L}}{\\partial {\\bf x}^{(l)}}$\n",
        " - `update` modifică parametrii locali ${\\bf \\theta}^{(l)}$ folosing gradientul stocat $\\frac{\\partial{\\cal L}}{\\partial{\\bf \\theta}^{(l)}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW206j3euJuf"
      },
      "source": [
        "class Layer:\n",
        "\n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def backward(self, x: np.ndarray, dy: np.ndarray) -> np.ndarray:\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def update(self, *args, **kwargs):\n",
        "        pass  # If a layer has no parameters, then this function does nothing"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIT6K4IduJuk"
      },
      "source": [
        "### Rețeaua neurală\n",
        "\n",
        "  * în faza `forward` ieșirile stratului $l$ devin intrările stratului $l+1$: ${\\bf x}^{(l+1)} = {\\bf y}^{(l)}$\n",
        "  * în faza `backward` gradientul în raport cu intrările stratului $l+1$ devine gradientul în raport cu ieșirile stratului $l$: $\\frac{\\partial {\\cal L}}{\\partial {\\bf y}^{(l)}}=\\frac{\\partial {\\cal L}}{\\partial {\\bf x}^{(l+1)}}$\n",
        "  \n",
        "**[Cerința 0]** Completați metoda `backward` din clasa `FeedForwardNetwork`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTn-g3KAuJul"
      },
      "source": [
        "class FeedForwardNetwork:\n",
        "    \n",
        "    def __init__(self, layers: List[Layer]):\n",
        "        self.layers = layers\n",
        "        \n",
        "    def forward(self, x: np.ndarray, train: bool = True) -> np.ndarray:\n",
        "        self._inputs = []\n",
        "        for layer in self.layers:\n",
        "            if train:\n",
        "                self._inputs.append(x)\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "    \n",
        "    def backward(self, dy:np.ndarray) -> np.ndarray:\n",
        "        # TODO <0> : Compute the backward phase\n",
        "        # Start with the gradient of the loss wrt the last output y\n",
        "        dx = dy\n",
        "        \n",
        "        # Propagate gradients through the network layers\n",
        "        for layer, x in zip(reversed(self.layers), reversed(self._inputs)):\n",
        "            dx = layer.backward(x, dx)\n",
        "        \n",
        "        del self._inputs\n",
        "        return dx\n",
        "\n",
        "\n",
        "    \n",
        "    def update(self, *args, **kwargs):\n",
        "        for layer in self.layers:\n",
        "            layer.update(*args, **kwargs)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyQLVM4quJup"
      },
      "source": [
        "### Stratul linear\n",
        "\n",
        "Un strat linear cu $M$ intrări și $N$ ieșiri are parametrii $\\theta = \\left( {\\bf W}, {\\bf b} \\right)$ unde ${\\bf W} \\in \\mathbb{R}^{M \\times N}$ și ${\\bf b} \\in \\mathbb{R}^{N}$.\n",
        "\n",
        "Pentru un singur exemlu ${\\bf x} \\in {\\mathbb R}^{M}$:\n",
        "$$ {\\bf y} = {\\bf x}^{\\intercal}{\\bf W} + {\\bf b} $$\n",
        "\n",
        "**[Cerința 1]** Implementați metoda `forward` care primește un batch de exemple $X \\in {\\mathbb R}^{B\\times M}$ și întoarce ieșirile corespunzătoare: $Y \\in {\\mathbb R}^{B\\times N}$.\n",
        "\n",
        "**[Cerința 2]** Implementați metoda `backward` care primește un batch de exemple $X \\in {\\mathbb R}^{B\\times M}$ și gradientul în raport cu ieșirile $\\frac{\\partial {\\cal L}}{\\partial {\\bf Y}}$ și realizează două lucruri:\n",
        "  - calculează și salvează intern gradientul $\\frac{\\partial {\\cal L}}{\\partial {\\bf \\theta}}$\n",
        "  - calculează și întoarce gradientul $\\frac{\\partial {\\cal L}}{\\partial {\\bf X}}$\n",
        "  \n",
        "**[BONUS][Cerința 9]** Implementați strategia de optimizare SGD cu _momentum_ (în metoda `update`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S47ZsyKdE7FF"
      },
      "source": [
        "class Linear(Layer):\n",
        "    \n",
        "    def __init__(self, insize: int, outsize: int) -> None:\n",
        "        bound = np.sqrt(6. / insize)\n",
        "        self.weight = np.random.uniform(-bound, bound, (insize, outsize))\n",
        "        self.bias = np.zeros((outsize,))\n",
        "        \n",
        "        self.dweight = np.zeros_like(self.weight)\n",
        "        self.dbias = np.zeros_like(self.bias)\n",
        "\n",
        "        \n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "         # Compute the output of a linear layer\n",
        "         self._last_input = x\n",
        "         y = x @ self.weight + self.bias\n",
        "         return y\n",
        "    \n",
        "    def backward(self, x: np.ndarray, dy: np.ndarray) -> np.ndarray:\n",
        "        # Compute dweight, dbias and return dx\n",
        "        # calculează și salvează intern gradientul intrările dx\n",
        "        dx = dy @ self.weight.T\n",
        "        self.dweight = self._last_input.T @ dy\n",
        "        self.dbias = np.sum(dy, axis=0)\n",
        "        return dx\n",
        "\n",
        "    \n",
        "    def update(self, mode='SGD', lr=0.001, mu=0.9):\n",
        "        if mode == 'SGD':\n",
        "            self.weight -= lr * self.dweight\n",
        "            self.bias -= lr * self.dbias\n",
        "        elif mode == 'momentum':\n",
        "            # TODO <9>: implement momentum update\n",
        "            v_weight = mu * self.dweight\n",
        "            v_bias = mu * self.dbias\n",
        "            self.weight -= lr * (self.dweight + v_weight)\n",
        "            self.bias -= lr * (self.dbias + v_bias)\n",
        "        else:\n",
        "            raise ValueError('mode should be SGD or momentum, not ' + str(mode))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgfHlVgDuJut"
      },
      "source": [
        "### The Rectified Linear Unit\n",
        "\n",
        "Stratul ReLU aplică următoare următoare transformare neliniară element cu element:\n",
        "$$y = \\max\\left(x, 0\\right)$$\n",
        "\n",
        "**[Cerințele 3-4]** Implementați metodele `forward` și `backward` pentru un strat de activare ReLU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOR1DJiwE7FJ"
      },
      "source": [
        "class ReLU(Layer):\n",
        "    \n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "    \n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        # Compute the output of a rectified linear unit\n",
        "        return np.maximum(x, 0)\n",
        "    \n",
        "    def backward(self, x: np.ndarray, dy: np.ndarray) -> np.ndarray:\n",
        "        # Compute the gradient w.r.t. x\n",
        "        return dy * (x > 0)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NrWBTmbI9gW"
      },
      "source": [
        "## 3. Funcția de cost\n",
        "\n",
        "Funcția de cost pe care o vom folosi este _cross entropy_ care combină un _softmax_ și un cost _negative log-likelihood_. (Matematica la tablă)\n",
        "\n",
        "Dacă ${\\bf y}$ reprezintă ieșrile rețelei pentru o intrare ${\\bf x}$, atunci ${\\bf y}$ va avea o dimensiune egală cu numărul de clase $K$. Atunci probabilitatea (prezisă de rețea) ca exemplul ${\\bf x}$ să aparțină clasei $k$ va fi $p_k$:\n",
        "$$\\begin{align}\n",
        "p_k &= \\frac{e^{y_k}}{\\sum_j e^{y_j}} & & \\text{softmax} \\\\\n",
        "{\\cal L} &= -\\log p_t & & \\text{negative log-likelihood}\n",
        "\\end{align}$$\n",
        "\n",
        "\n",
        "Pentru un batch de dimensiune $B$ se va face media costurilor corespunzătare fiecărui exemplu ($p_k$ este o funcție de ${\\bf x}$ și ${\\bf \\theta}$):\n",
        "\n",
        "$$ {\\cal L} = \\frac{1}{B} \\sum_{({\\bf x}, {\\bf t}) \\in Batch} -\\log p_t \\left({\\bf x}, \\theta\\right) $$\n",
        "\n",
        "**[Cerințele 5-6]** Implementați metodele `forward` și `backward` pentru un funcția de cost _cross-entropy_ (o vom privi ca pe un strat suplimentar)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDXiDEu8E7FW"
      },
      "source": [
        "class CrossEntropy:\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, y: np.ndarray, t: np.ndarray) -> float:\n",
        "        # clip y to avoid numerical instability when computing the log\n",
        "        y = np.clip(y, 1e-15, 1 - 1e-15)\n",
        "        # get the probability of the true class\n",
        "        p = y[np.arange(len(y)), t]\n",
        "        # compute the negative log likelihood\n",
        "        loss = -np.sum(np.log(p)) / len(p)\n",
        "        return loss\n",
        "    \n",
        "    def backward(self, y: np.ndarray, t: np.ndarray) -> np.ndarray:\n",
        "        # create a one-hot encoding of the targets\n",
        "        onehot = np.zeros_like(y)\n",
        "        onehot[np.arange(len(t)), t] = 1\n",
        "        # compute dl/dy\n",
        "        dy = (y - onehot) / len(y)\n",
        "        return dy\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz9qM5eHJLNw"
      },
      "source": [
        "### Acuratețea\n",
        "\n",
        "**[Cerința 7]** Calculați acuratețea predicțiilor ${\\bf y}$ în raport cu clasele corecte ${\\bf t}$ (rația exemplelor pentru care clasa corectă a avut probabilitatea prezisă maximă)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nYfVCBSE7Fe"
      },
      "source": [
        "def accuracy(y: np.ndarray, t: np.ndarray) -> float:\n",
        "    y_argmax = np.argmax(y, axis=1)\n",
        "    t_argmax = np.argmax(t, axis=1)\n",
        "    num_correct = np.sum(y_argmax == t_argmax)\n",
        "    num_total = y.shape[0]\n",
        "    return num_correct / num_total\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIhtzd2gJQF2"
      },
      "source": [
        "## 4. Antrenarea rețelei neurale\n",
        "\n",
        "**[Cerința 8]** Completați codul de mai jos pentru a calcula gradientul funcției de cost pentru batchul ales și parametrii curenți ai rețelei. _Indiciu_: trebuie să apelați metodele `forward` și `backward` ale rețelei neurale și ale funcției de cost.\n",
        "\n",
        "**[BONUS]** Implementați optimizare cu _momentum_ (vezi TODO-ul numărul 9 din metoda `update`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTbmZv3YE7Fs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "085c0e09-38bf-436d-f090-8cba5f5b7f52"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "HIDDEN_UNITS = 300\n",
        "EPOCHS_NO = 20\n",
        "\n",
        "optimize_args = {'mode': 'SGD', 'lr': .005}\n",
        "\n",
        "net = FeedForwardNetwork([Linear(784, HIDDEN_UNITS),\n",
        "                          ReLU(),\n",
        "                          Linear(HIDDEN_UNITS, 10)])\n",
        "cost_function = CrossEntropy()\n",
        "\n",
        "for epoch in range(EPOCHS_NO):\n",
        "    for b_no, idx in enumerate(range(0, len(train_imgs), BATCH_SIZE)):\n",
        "        # 1. Prepare next batch\n",
        "        x = train_imgs[idx:idx + BATCH_SIZE,:,:].reshape(-1, 784)\n",
        "        t = train_labels[idx:idx + BATCH_SIZE]\n",
        "        \n",
        "        # 2. Compute gradient\n",
        "        \n",
        "        # TODO <8> : Compute gradient\n",
        "        y = net.forward(x, train=True)\n",
        "        loss = cost_function.forward(y, t)\n",
        "        dl_dy = cost_function.backward(y, t)\n",
        "        net.backward(dl_dy)\n",
        "        \n",
        "        # 3. Update network parameters\n",
        "        net.update(**optimize_args)\n",
        "        \n",
        "        print(f'\\rEpoch {epoch + 1:02d} '\n",
        "              f'| Batch {b_no:03d} '\n",
        "              f'| Train NLL: {loss:6.3f} '\n",
        "              f'| Train Acc: {accuracy(y, t) * 100:6.2f}% ', end='')\n",
        "\n",
        "    y = net.forward(test_imgs.reshape(-1, 784), train=False)\n",
        "    test_nll = cost_function.forward(y, test_labels)\n",
        "    print(f'| Test NLL: {test_nll:6.3f} '\n",
        "          f'| Test Acc: {accuracy(y, test_labels) * 100:3.2f}%')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-900d6108cf33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m               \u001b[0;34mf'| Batch {b_no:03d} '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m               \u001b[0;34mf'| Train NLL: {loss:6.3f} '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m               f'| Train Acc: {accuracy(y, t) * 100:6.2f}% ', end='')\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-1695a718f58c>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(y, t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0my_argmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mt_argmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnum_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_argmax\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt_argmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \"\"\"\n\u001b[1;32m   1215\u001b[0m     \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'keepdims'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7zGgHlduJvA"
      },
      "source": [
        "## Teste\n",
        "\n",
        "Executați ```test0() and test16() and test7()``` pentru a rula testele."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YaLsPBfuJvB"
      },
      "source": [
        "def test0():\n",
        "    fakex = [np.random.randn(128, n) for n in [20, 40, 30, 10]]\n",
        "\n",
        "    class DummyLayer:\n",
        "        def __init__(self, idx):\n",
        "            self.idx = idx\n",
        "\n",
        "        def forward(self, x):\n",
        "            return fakex[self.idx + 1]\n",
        "\n",
        "        def backward(self, x, dldy):\n",
        "            if not np.allclose(x, fakex[self.idx]):\n",
        "                raise Exception(\"Intrări greșite în backward\")\n",
        "            if not np.allclose(dldy, -fakex[self.idx+1]):\n",
        "                raise Exception(\"Intrări greșite în backward\")\n",
        "            return -x\n",
        "\n",
        "    try:\n",
        "        net = FeedForwardNetwork([DummyLayer(i) for i in range(3)])\n",
        "        net.forward(fakex[0])\n",
        "        net.backward(-fakex[-1])\n",
        "        print(\"Cerința 0 rezolvată corect!\")\n",
        "        return True\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 0 nu a fost implementată!\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 0 are erori.\")\n",
        "        \n",
        "    return False\n",
        "        \n",
        "def test16():\n",
        "    __x = np.array([[-3.0731, -1.9081, -0.7283, -0.0757, -0.7577],\n",
        "                    [ 2.4041, -1.1506, -0.5924,  1.3016,  1.0882],\n",
        "                    [-0.5254,  0.3519, -0.9633, -2.7393, -0.9745]])\n",
        "    __w = np.array([[ 1.3214, -0.5886, -0.0351,  1.2084,  1.2661, -0.9979, -0.1172],\n",
        "                    [-0.4022,  0.1168,  0.9020, -2.0098, -0.5409, -0.3876, -0.1719],\n",
        "                    [-1.1125, -0.5556,  0.8843,  0.6995,  0.4929,  0.7523,  0.1832],\n",
        "                    [ 0.2267,  0.6757,  1.1286, -0.3218,  1.6934, -0.1782, -0.3467],\n",
        "                    [-0.6062,  0.4426,  0.5090,  0.4772, -0.5721,  0.8658, -0.5999]])\n",
        "    __b = np.array([ 0.3335,  0.5051, -0.1393,  1.2116,  1.7836, -0.6597,  0.3553])\n",
        "    __y = np.array([[-1.70746622, 2.10919555, -2.8676804, 0.48630531, -1.1288499, 1.95609904, 1.39083457],\n",
        "                    [4.26749994, 0.64592254, 0.23749513, 6.11524068, 6.73936681, -2.34822291, -0.94127596],\n",
        "                    [0.5391161, -0.89159687, -4.24288533, -0.38789499, -3.62798139, -1.35206921, 1.71422657]])\n",
        "    \n",
        "    __dy = np.array([[ 1.5555, -0.8978, -0.2917, -0.3868, -0.8257, -0.3491, -0.8658],\n",
        "                     [ 1.1146,  1.4914,  0.9591, -0.2613,  0.5887,  0.4794,  0.8565],\n",
        "                     [-0.1552, -1.6319,  1.7642,  1.0503,  0.1035 , -0.7186, -0.9782]])\n",
        "    __dx = np.array([[ 1.53113221,  0.51455541, -2.588423,   -1.49460989, -0.98384103],\n",
        "                     [ 0.41215308,  0.46469672, -0.59552791,  3.04147235, -0.08763244],\n",
        "                     [ 2.92549149, -0.25707023,  2.70531668,  1.15769427,  0.67643021]])\n",
        "    __dw = np.array(\n",
        "        [[-2.01905511,  7.20190418,  2.2752849,   0.00865613,  3.89837344,  2.60289719, 5.23374791],\n",
        "         [-4.30512319, -0.57717827,  0.07387429,  1.40830543,  0.9345816,  -0.13835527, 0.3223155 ],\n",
        "         [-1.64365553,  1.34237165, -2.05517959, -0.57525343,  0.15290988,  0.66248035, 1.0654716 ],\n",
        "         [ 1.75815137,  6.47943337, -3.56222681, -3.18791411,  0.54523986,  2.61887489, 3.85994472],\n",
        "         [ 0.18554777,  3.89349109, -0.45449919, -1.01478565,  1.16539548,  1.48647185, 2.54131586]]\n",
        "    )\n",
        "    __db = np.array([ 2.5149, -1.0383,  2.4316,  0.4022, -0.1335, -0.5883, -0.9875])\n",
        "    \n",
        "    __y_relu = np.array([[0, 2.10919555, 0, 0.48630531, 0, 1.95609904, 1.39083457],\n",
        "                         [4.26749994, 0.64592254, 0.23749513, 6.11524068, 6.73936681, 0, 0],\n",
        "                         [0.5391161, 0, 0, 0, 0, 0, 1.71422657]])\n",
        "    __drelu = np.array([[0, -0.8978, 0, -0.3868, 0, -0.3491, -0.8658],\n",
        "                        [ 1.1146,  1.4914,  0.9591, -0.2613,  0.5887,  0,  0],\n",
        "                        [-0.1552, 0,  0,  0,  0 , 0, -0.9782]])\n",
        "    \n",
        "    __t = np.array([3, 1, 2])\n",
        "    __dl_dy = np.array(\n",
        "        [[ 2.80870645e-03,  1.27661957e-01,  8.80302096e-04, -3.08142112e-01,\n",
        "           5.00952130e-03,  1.09539948e-01,  6.22416775e-02],\n",
        "         [ 1.73238217e-02, -3.32870086e-01,  3.07917841e-04,  1.09927743e-01,\n",
        "           2.05192672e-01,  2.31991342e-05,  9.47329526e-05],\n",
        "         [ 6.60308812e-02,  1.57905168e-02, -3.32780047e-01,  2.61307149e-02,\n",
        "           1.02329216e-03,  9.96358772e-03,  2.13841054e-01]]\n",
        "    )\n",
        "\n",
        "\n",
        "    try:\n",
        "        lin = Linear(5, 7)\n",
        "        lin.weight = __w.copy()\n",
        "        lin.bias = __b.copy()\n",
        "        y = lin.forward(__x.copy())\n",
        "        if not np.allclose(y, __y):\n",
        "            raise Exception(\"Ieșiri greșite\")\n",
        "        print(\"Cerința 1 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 1 nu a fost implementată!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 1 are erori.\")\n",
        "        return False\n",
        "        \n",
        "    try:\n",
        "        dx = lin.backward(__x.copy(), __dy.copy())\n",
        "        if not np.allclose(dx, __dx):\n",
        "            raise ValueError(\"dL/dx greșit\")\n",
        "        if not np.allclose(lin.dweight, __dw):\n",
        "            raise ValueError(\"dL/dw greșit\")\n",
        "        if not np.allclose(lin.dbias, __db):\n",
        "            raise ValueError(\"dL/db greșit\")\n",
        "        print(\"Cerința 2 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 2 nu a fost implementată!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 2 are erori.\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        relu = ReLU()\n",
        "        y_relu = relu.forward(__y.copy())\n",
        "        if not np.allclose(y_relu, __y_relu):\n",
        "            raise ValueError(\"ReLU(x) greșit\")\n",
        "        print(\"Cerința 3 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 3 nu a fost implementată!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 3 are erori.\")\n",
        "        return False\n",
        "            \n",
        "    try:\n",
        "        relu = ReLU()\n",
        "        drelu = relu.backward(__y.copy(), __dy.copy())\n",
        "        if not np.allclose(drelu, __drelu):\n",
        "            raise ValueError(\"ReLU.backward greșit\")\n",
        "        print(\"Cerința 4 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 4 nu a fost implementată!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 4 are erori.\")\n",
        "        return False\n",
        "    \n",
        "    try:\n",
        "        ce = CrossEntropy()\n",
        "        loss = ce.forward(__y.copy(), __t.copy())\n",
        "        if np.abs(loss - 5.1874357237332545) > 1e-6:\n",
        "            raise ValueError(f\"Valoare greșită nll: {loss:f} în loc de 5.1874357237332545\")\n",
        "        print(\"Cerința 5 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 5 nu a fost implementată!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 5 are erori.\")\n",
        "        return False\n",
        "    \n",
        "    try:\n",
        "        ce = CrossEntropy()\n",
        "        dl_dy = ce.backward(__y.copy(), __t.copy())\n",
        "        if not np.allclose(dl_dy, __dl_dy) > 1e-6:\n",
        "            raise ValueError(f\"Valoare greșită pentru dNLL/dy\")\n",
        "        print(\"Cerința 6 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 6 nu a fost implementată!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 6 are erori.\")\n",
        "        return False\n",
        "    \n",
        "    return True\n",
        "\n",
        "def test7():  # Acuratețea\n",
        "    y = np.array([[ 0.6460014 , -0.05876393, -1.36496105, -0.07057596,  0.54938383],\n",
        "                  [-0.8033942 , -0.51753041,  0.92278036, -1.66303585, -0.36537512],\n",
        "                  [-1.3710599 ,  0.65598193, -0.75527154,  1.21609284,  0.08284123],\n",
        "                  [-1.24696857,  0.32676634,  0.09572539,  1.38316398, -0.14110726],\n",
        "                  [-2.01698315,  2.06123375, -1.68003675,  0.0504592 ,  0.04427597],\n",
        "                  [-0.8893451 ,  1.74695148, -0.29394473,  0.74203068, -0.75185261],\n",
        "                  [ 1.34126333, -0.5272606 ,  1.46458319,  1.59529987,  1.86884676],\n",
        "                  [-0.58987297,  1.10900165, -0.71208103,  0.20478154, -1.26693567],\n",
        "                  [-2.17730677, -1.36147532, -1.49679182,  0.24812177, -0.13368035],\n",
        "                  [-0.48730599,  1.31710647,  0.41765538,  1.19869192, -0.05301611],\n",
        "                  [-0.10655224, -0.21174034,  1.31548647, -0.57990281,  0.85868472],\n",
        "                  [-0.32055613, -2.17817118, -0.28488692,  1.62977524,  0.25150929],\n",
        "                  [ 0.07704727,  1.67710047,  1.83368441, -0.45456845, -0.74474969]])\n",
        "    t = np.array([0, 2, 3, 3, 1, 0, 1, 1, 2, 1, 2, 3, 2])\n",
        "    try:\n",
        "        acc = accuracy(y, t)\n",
        "        if np.abs(acc - 0.7692307692307693) > 1e-7:\n",
        "            raise ValueError(f\"{acc:f} != 10/13\")\n",
        "        print(f\"Cerința 7 rezolvată corect!\")\n",
        "    except NotImplementedError as e:\n",
        "        print(\"Cerința 7 nu a fost implementată!\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(\"Cerința 7 are erori.\")\n",
        "    "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWQ2e7C4uJvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8447719-4293-4f41-be80-36c9e8ca3b34"
      },
      "source": [
        "test0() and test16() and test7()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cerința 0 rezolvată corect!\n",
            "Cerința 1 rezolvată corect!\n",
            "Cerința 2 rezolvată corect!\n",
            "Cerința 3 rezolvată corect!\n",
            "Cerința 4 rezolvată corect!\n",
            "Valoare greșită nll: 11.898924 în loc de 5.1874357237332545\n",
            "Cerința 5 are erori.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}
